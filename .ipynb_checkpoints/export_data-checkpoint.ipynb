{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e381558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://read_aistt:****@code.officialstatistics.org/trade-task-team-phase-1/ais.git\n",
      "  Cloning https://read_aistt:****@code.officialstatistics.org/trade-task-team-phase-1/ais.git to /tmp/pip-req-build-g2gly0wz\n",
      "Building wheels for collected packages: ais\n",
      "  Building wheel for ais (setup.py): started\n",
      "  Building wheel for ais (setup.py): finished with status 'done'\n",
      "  Created wheel for ais: filename=ais-2.7.4-py3-none-any.whl size=9163 sha256=a2d815a58401910a8a056e2219b87553c57f546f6d37fa9f68a05a21b08ab191\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-7188mn_8/wheels/6d/8c/5e/19898a2b930f8efa2ef2e6ecc8ef48797422e3ec7e0114b312\n",
      "Successfully built ais\n",
      "Installing collected packages: ais\n",
      "Successfully installed ais-2.7.4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "GITLAB_USER = \"read_aistt\"  #For use of members of AIS Task Team, read only access\n",
    "GITLAB_TOKEN = \"J1Kk8tArfyXB6dZvFcWW\"\n",
    "git_package = f\"git+https://{GITLAB_USER}:{GITLAB_TOKEN}@code.officialstatistics.org/trade-task-team-phase-1/ais.git\"\n",
    "\n",
    "std_out = subprocess.run([sys.executable, \"-m\", \"pip\", \"install\",git_package], capture_output=True, text=True).stdout\n",
    "print(std_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d62af339",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ais import functions as af\n",
    "\n",
    "#still need to register Sedona even with template configuration. need to check why\n",
    "from sedona.register import SedonaRegistrator\n",
    "SedonaRegistrator.registerAll(spark)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from IPython.display import display\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import h3\n",
    "import h3.api.numpy_int as h3int\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "import os\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d633c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get clone the repo\n",
    "try:\n",
    "    std_out = subprocess.run([\"git\", \"clone\", \"https://github.com/CSBP-CPSE/ais-data.git\"],\n",
    "                             capture_output=True,\n",
    "                             text=True)\n",
    "    print(std_out)\n",
    "    print(os.listdir())\n",
    "except:\n",
    "    print(\"Cloning repo failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa95ef91",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Get data from earlist date to 2022-08-01\n",
    "start_date = datetime.fromisoformat(\"2018-12-01\") # Earliest date\n",
    "end_date = datetime.fromisoformat(\"2022-08-01\")\n",
    "df = af.get_ais(spark, start_date=start_date, end_date=end_date)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f735eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define polygon for vancouver port\n",
    "vanPort = { \"type\": \"Polygon\", \n",
    "            \"coordinates\": [ \n",
    "                [ \n",
    "                    [-123.212426525887096, 49.274760228402968],\n",
    "                    [-122.985548446858502, 49.251700411088592], \n",
    "                    [-122.988952264515504, 49.355219640768908],\n",
    "                    [-123.214802962515606, 49.353944465477369],\n",
    "                    [-123.212426525887096, 49.274760228402968]\n",
    "                ]\n",
    "            ]\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb10ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Filter by geography\n",
    "df_van = af.apply_geo_filter(spark, df, vanPort)\n",
    "\n",
    "df_van.count()\n",
    "\n",
    "# Takes a few mins (5 mins 30s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2bf6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "# Try to convert it to pandas df\n",
    "try:\n",
    "    df_van = df_van.toPandas()\n",
    "    display(df_van)\n",
    "    print(df_van['dt_pos_utc'].min())\n",
    "    print(df_van['dt_pos_utc'].max())\n",
    "except:\n",
    "    print(\"The dataframe was too large to convert to Pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19aece97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop row on 2022-06-30\n",
    "df_van = df_van[\"2022-06-01 00:00:01\" <= df_van['dt_pos_utc']]\n",
    "df_van = df_van[df_van['dt_pos_utc'] <= \"2022-06-30 23:59:59\"]\n",
    "df_van.reset_index(drop=True)\n",
    "\n",
    "print(df_van['dt_pos_utc'].min())\n",
    "print(len(df_van.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898333fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split DF into smaller files and save them to csv\n",
    "list_df = np.array_split(df_van, 10)\n",
    "\n",
    "# Create Data folder if it doesn't exist\n",
    "if os.path.exists(\"./ais-data/Data/\") is False:\n",
    "    os.mkdir(\"./ais-data/Data/\")\n",
    "\n",
    "for i in range(len(list_df)):\n",
    "    list_df[i].to_csv(\"./ais-data/Data/van_port_{}.csv\".format(i), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d58028a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change directory\n",
    "os.chdir(\"./ais-data\")\n",
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184a814b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Git Config\n",
    "std_out = subprocess.run([\"git\", \"config\", \"--global\", \"user.email\", '\"dennishuynh3@gmail.com\"'], capture_output=True, text=True)\n",
    "print(std_out)\n",
    "std_out = subprocess.run([\"git\", \"config\", \"--global\", \"user.name\", '\"DennisH3\"'], capture_output=True, text=True)\n",
    "print(std_out)\n",
    "\n",
    "# Git add and commit\n",
    "std_out = subprocess.run([\"git\", \"add\", \".\"], capture_output=True, text=True)\n",
    "print(std_out)\n",
    "std_out = subprocess.run([\"git\", \"commit\", \"-m\", \"Remove data\"], capture_output=True, text=True)\n",
    "print(std_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1b8af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get credentials\n",
    "un = \"DennisH3\"\n",
    "pw = getpass.getpass(prompt=\"Please enter PAT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196fbd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "push = \"git push --repo https://{}:{}@github.com/CSBP-CPSE/ais-data.git\".format(un, pw)\n",
    "\n",
    "std_out = subprocess.run([push], capture_output=True, text=True, shell=True).stderr\n",
    "print(std_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Config template \"newparquet-20220310\"",
   "language": "python3",
   "name": "newparquet-20220310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
