{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e381558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://read_aistt:****@code.officialstatistics.org/trade-task-team-phase-1/ais.git\n",
      "  Cloning https://read_aistt:****@code.officialstatistics.org/trade-task-team-phase-1/ais.git to /tmp/pip-req-build-pdf7ktll\n",
      "Building wheels for collected packages: ais\n",
      "  Building wheel for ais (setup.py): started\n",
      "  Building wheel for ais (setup.py): finished with status 'done'\n",
      "  Created wheel for ais: filename=ais-2.7.5-py3-none-any.whl size=9195 sha256=89b5c33207d4ee8a64a0158105dc02b5c19e21b42b9055c19557a133ed15e8e7\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-u2d9gqrc/wheels/6d/8c/5e/19898a2b930f8efa2ef2e6ecc8ef48797422e3ec7e0114b312\n",
      "Successfully built ais\n",
      "Installing collected packages: ais\n",
      "Successfully installed ais-2.7.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "GITLAB_USER = \"read_aistt\"  #For use of members of AIS Task Team, read only access\n",
    "GITLAB_TOKEN = \"J1Kk8tArfyXB6dZvFcWW\"\n",
    "git_package = f\"git+https://{GITLAB_USER}:{GITLAB_TOKEN}@code.officialstatistics.org/trade-task-team-phase-1/ais.git\"\n",
    "\n",
    "std_out = subprocess.run([sys.executable, \"-m\", \"pip\", \"install\",git_package], capture_output=True, text=True).stdout\n",
    "print(std_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "335e4bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ais import functions as af\n",
    "\n",
    "#still need to register Sedona even with template configuration. need to check why\n",
    "from sedona.register import SedonaRegistrator\n",
    "SedonaRegistrator.registerAll(spark)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from IPython.display import display\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import h3\n",
    "import h3.api.numpy_int as h3int\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "import os\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "890caffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletedProcess(args=['git', 'clone', 'https://github.com/CSBP-CPSE/ais-data.git'], returncode=0, stdout='', stderr=\"Cloning into 'ais-data'...\\nChecking out files:  30% (9/30)   \\nChecking out files:  33% (10/30)   \\nChecking out files:  36% (11/30)   \\nChecking out files:  40% (12/30)   \\nChecking out files:  43% (13/30)   \\nChecking out files:  46% (14/30)   \\nChecking out files:  50% (15/30)   \\nChecking out files:  53% (16/30)   \\nChecking out files:  56% (17/30)   \\nChecking out files:  60% (18/30)   \\nChecking out files:  63% (19/30)   \\nChecking out files:  66% (20/30)   \\nChecking out files:  70% (21/30)   \\nChecking out files:  73% (22/30)   \\nChecking out files:  76% (23/30)   \\nChecking out files:  80% (24/30)   \\nChecking out files:  83% (25/30)   \\nChecking out files:  86% (26/30)   \\nChecking out files:  90% (27/30)   \\nChecking out files:  93% (28/30)   \\nChecking out files:  96% (29/30)   \\nChecking out files: 100% (30/30)   \\nChecking out files: 100% (30/30), done.\\n\")\n",
      "['ais-data', 'requirements.txt', 'launch_ipykernel.py']\n"
     ]
    }
   ],
   "source": [
    "# Get clone the repo\n",
    "try:\n",
    "    std_out = subprocess.run([\"git\", \"clone\", \"https://github.com/CSBP-CPSE/ais-data.git\"],\n",
    "                             capture_output=True,\n",
    "                             text=True)\n",
    "    print(std_out)\n",
    "    print(os.listdir())\n",
    "except:\n",
    "    print(\"Cloning repo failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a802a8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2249\n"
     ]
    }
   ],
   "source": [
    "# Load port coordinates\n",
    "ports = pd.read_csv(\"./ais-data/ODI_Marine_Ports_v0.1.csv\",\n",
    "                    usecols=['MunicipalityName', 'ERNAME', 'Latitude', 'Longitude'])\n",
    "\n",
    "# Filter for top 20 ports according to https://www144.statcan.gc.ca/nats-stna/tables-tableaux/tbl11-4a/tbl11-4a-CAN-eng.htm\n",
    "# St Romuald is the only one in Lévis\n",
    "top20 = ['Vancouver', 'Saint John', 'Montréal', 'Hamilton', 'Halifax', 'Windsor']\n",
    "ports = ports[(ports['ERNAME'].str.contains('|'.join(top20), case=False)) | \n",
    "              (ports['MunicipalityName'].isin(['Come-by-Chance', 'St Romuald', \n",
    "                                               'Strait of Canso Port(Formerly Port Hawkesbury)',\n",
    "                                               'Port of Sorel', 'Nanticoke', 'Baie-Comeau',\n",
    "                                               'Sault-Ste-Marie', 'Port Alfred']))]\n",
    "display(ports)\n",
    "\n",
    "# Recommended to try resolution sizes of 6-9 from Port Indicators Demo\n",
    "# Use resolution 8 with radius of 2\n",
    "ports['H3_int_index_8'] = ports[['Latitude','Longitude']].apply(lambda x: h3.geo_to_h3(x[0],x[1], 8), axis=1)\n",
    "ports['h8_rings'] = ports['H3_int_index_8'].apply(lambda x: list(h3.k_ring(x, 2)))\n",
    "ports = ports.explode('h8_rings', ignore_index=True)\n",
    "ports['h8_rings_decimal'] = ports['h8_rings'].apply(lambda x: int(x, 16))\n",
    "ports = ports['h8_rings_decimal'].unique().tolist()\n",
    "\n",
    "print(len(ports))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eb8dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Get data from earliest date to 2022-08-01\n",
    "start_date = datetime.fromisoformat(\"2018-12-01\") # Earliest date (2018-12-01)\n",
    "end_date = start_date + pd.DateOffset(months=1) # Add 1 month\n",
    "df = af.get_ais(spark,\n",
    "                start_date=start_date,\n",
    "                end_date=end_date,\n",
    "                h3_list=ports)\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850a657e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique values in vessel_type_cargo and vessel_class\n",
    "# df.select('vessel_type').distinct().show(n=50, truncate=False)\n",
    "\n",
    "# Output:\n",
    "# +------------------------------------+\n",
    "# |vessel_type                         |\n",
    "# +------------------------------------+\n",
    "# |Sailing                             |\n",
    "# |Tanker                              |\n",
    "# |Military                            |\n",
    "# |Towing                              |\n",
    "# |Reserved                            |\n",
    "# |SAR                                 |\n",
    "# |Unknown                             |\n",
    "# |UNAVAILABLE                         |\n",
    "# |Other                               |\n",
    "# |Tug                                 |\n",
    "# |Law Enforcement                     |\n",
    "# |Pleasure Craft                      |\n",
    "# |Passenger                           |\n",
    "# |Diving                              |\n",
    "# |Fishing                             |\n",
    "# |Port Tender                         |\n",
    "# |Spare                               |\n",
    "# |Pilot                               |\n",
    "# |WIG                                 |\n",
    "# |Dredging                            |\n",
    "# |Not Available                       |\n",
    "# |Cargo                               |\n",
    "# |Vessel With Anti-Pollution Equipment|\n",
    "# |HSC                                 |\n",
    "# +------------------------------------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33b4be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by vessel type\n",
    "# vessel_list = ['Cargo', 'Tanker']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a890b83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataframe was too large to convert to Pandas\n",
      "CPU times: user 30.3 ms, sys: 3.69 ms, total: 34 ms\n",
      "Wall time: 5min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Try to convert it to pandas df\n",
    "try:\n",
    "    df = df.toPandas()\n",
    "    display(df)\n",
    "    print(df['dt_pos_utc'].min())\n",
    "    print(df['dt_pos_utc'].max())\n",
    "except:\n",
    "    print(\"The dataframe was too large to convert to Pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2786ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any dates exceeding the 1 month interval\n",
    "df = df[str(start_date) <= df['dt_pos_utc']]\n",
    "df = df[df['dt_pos_utc'] <= str(end_date - timedelta(seconds=1))]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Check new max\n",
    "print(df['dt_pos_utc'].max())\n",
    "print(len(df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e2d0c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split DF into smaller files and save them to csv\n",
    "\n",
    "# Each file will have 100000 rows\n",
    "list_df = np.array_split(df, (len(df.index) // 100000) + 1)\n",
    "\n",
    "# Create Data folder if it doesn't exist\n",
    "if os.path.exists(\"./ais-data/Data/\") is False:\n",
    "    os.mkdir(\"./ais-data/Data/\")\n",
    "\n",
    "for i in range(len(list_df)):\n",
    "    list_df[i].to_csv(\"./ais-data/Data/top20_ports_{}_to_{}_chunk_{}.csv\".format(datetime.date(start_date),\n",
    "                                                                                 datetime.date(end_date - timedelta(seconds=1)),\n",
    "                                                                                 i), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7668846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.git', '.ipynb_checkpoints', 'Data', 'ODI_Marine_Ports_v0.1.csv', 'README.md', 'ais_analysis.ipynb', 'export_data.ipynb', 'move_data.ipynb', 'vancouver_port.ipynb']\n",
      "['2021-04-01_to_2021-04-30_chunk_0.csv', '2021-04-01_to_2021-04-30_chunk_1.csv', '2021-04-01_to_2021-04-30_chunk_2.csv', '2021-04-01_to_2021-04-30_chunk_3.csv', '2021-04-01_to_2021-04-30_chunk_4.csv', '2021-04-01_to_2021-04-30_chunk_5.csv', '2021-04-01_to_2021-04-30_chunk_6.csv', '2021-05-01_to_2021-05-31_chunk_0.csv', '2021-05-01_to_2021-05-31_chunk_1.csv', '2021-05-01_to_2021-05-31_chunk_2.csv', '2021-05-01_to_2021-05-31_chunk_3.csv', '2021-05-01_to_2021-05-31_chunk_4.csv', '2021-05-01_to_2021-05-31_chunk_5.csv', '2021-05-01_to_2021-05-31_chunk_6.csv', '2021-06-01_to_2021-06-30_chunk_0.csv', '2021-06-01_to_2021-06-30_chunk_1.csv', '2021-06-01_to_2021-06-30_chunk_2.csv', '2021-06-01_to_2021-06-30_chunk_3.csv', '2021-06-01_to_2021-06-30_chunk_4.csv', '2021-06-01_to_2021-06-30_chunk_5.csv']\n"
     ]
    }
   ],
   "source": [
    "# Change directory\n",
    "os.chdir(\"./ais-data\")\n",
    "print(os.listdir())\n",
    "print(os.listdir(\"./Data/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2778ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletedProcess(args=['git', 'config', '--global', 'user.email', '\"dennishuynh3@gmail.com\"'], returncode=0, stdout='', stderr='')\n",
      "CompletedProcess(args=['git', 'config', '--global', 'user.name', '\"DennisH3\"'], returncode=0, stdout='', stderr='')\n",
      "CompletedProcess(args=['git', 'add', '.'], returncode=0, stdout='', stderr='')\n",
      "[main 9abaa44] Upload data\n",
      " 6 files changed, 593647 insertions(+)\n",
      " create mode 100644 Data/2021-06-01_to_2021-06-30_chunk_0.csv\n",
      " create mode 100644 Data/2021-06-01_to_2021-06-30_chunk_1.csv\n",
      " create mode 100644 Data/2021-06-01_to_2021-06-30_chunk_2.csv\n",
      " create mode 100644 Data/2021-06-01_to_2021-06-30_chunk_3.csv\n",
      " create mode 100644 Data/2021-06-01_to_2021-06-30_chunk_4.csv\n",
      " create mode 100644 Data/2021-06-01_to_2021-06-30_chunk_5.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Git Config\n",
    "std_out = subprocess.run([\"git\", \"config\", \"--global\", \"user.email\", '\"dennishuynh3@gmail.com\"'], capture_output=True, text=True)\n",
    "print(std_out)\n",
    "std_out = subprocess.run([\"git\", \"config\", \"--global\", \"user.name\", '\"DennisH3\"'], capture_output=True, text=True)\n",
    "print(std_out)\n",
    "\n",
    "# Git add and commit\n",
    "std_out = subprocess.run([\"git\", \"add\", \".\"], capture_output=True, text=True)\n",
    "print(std_out)\n",
    "std_out = subprocess.run([\"git\", \"commit\", \"-m\", \"Upload data\"], capture_output=True, text=True).stdout\n",
    "print(std_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77f45993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter PAT········\n"
     ]
    }
   ],
   "source": [
    "# Get credentials\n",
    "un = \"DennisH3\"\n",
    "pw = getpass.getpass(prompt=\"Please enter PAT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d5d55c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: warning: See http://git.io/iEPt8g for more information.        \n",
      "remote: warning: File Data/2021-06-01_to_2021-06-30_chunk_5.csv is 66.07 MB; this is larger than GitHub's recommended maximum file size of 50.00 MB        \n",
      "remote: warning: File Data/2021-06-01_to_2021-06-30_chunk_0.csv is 63.92 MB; this is larger than GitHub's recommended maximum file size of 50.00 MB        \n",
      "remote: warning: File Data/2021-06-01_to_2021-06-30_chunk_1.csv is 63.94 MB; this is larger than GitHub's recommended maximum file size of 50.00 MB        \n",
      "remote: warning: File Data/2021-06-01_to_2021-06-30_chunk_2.csv is 64.20 MB; this is larger than GitHub's recommended maximum file size of 50.00 MB        \n",
      "remote: warning: File Data/2021-06-01_to_2021-06-30_chunk_3.csv is 65.43 MB; this is larger than GitHub's recommended maximum file size of 50.00 MB        \n",
      "remote: warning: File Data/2021-06-01_to_2021-06-30_chunk_4.csv is 66.92 MB; this is larger than GitHub's recommended maximum file size of 50.00 MB        \n",
      "remote: warning: GH001: Large files detected. You may want to try Git Large File Storage - https://git-lfs.github.com.        \n",
      "To https://github.com/CSBP-CPSE/ais-data.git\n",
      "   d60d37e..9abaa44  main -> main\n",
      "\n"
     ]
    }
   ],
   "source": [
    "push = \"git push --repo https://{}:{}@github.com/CSBP-CPSE/ais-data.git\".format(un, pw)\n",
    "\n",
    "std_out = subprocess.run([push], capture_output=True, text=True, shell=True).stderr\n",
    "print(std_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d509570f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Config template \"newparquet-20220310\"",
   "language": "python3",
   "name": "newparquet-20220310"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
