{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e381558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://read_aistt:****@code.officialstatistics.org/trade-task-team-phase-1/ais.git\n",
      "  Cloning https://read_aistt:****@code.officialstatistics.org/trade-task-team-phase-1/ais.git to /tmp/pip-req-build-hoeu6v_x\n",
      "Building wheels for collected packages: ais\n",
      "  Building wheel for ais (setup.py): started\n",
      "  Building wheel for ais (setup.py): finished with status 'done'\n",
      "  Created wheel for ais: filename=ais-2.7.5-py3-none-any.whl size=9195 sha256=71dc64412c3db87e8a4071a4d40a04fa9092d2b4cb5660459f842c5fdea0d198\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-55g2ctmv/wheels/6d/8c/5e/19898a2b930f8efa2ef2e6ecc8ef48797422e3ec7e0114b312\n",
      "Successfully built ais\n",
      "Installing collected packages: ais\n",
      "Successfully installed ais-2.7.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "GITLAB_USER = \"read_aistt\"  #For use of members of AIS Task Team, read only access\n",
    "GITLAB_TOKEN = \"J1Kk8tArfyXB6dZvFcWW\"\n",
    "git_package = f\"git+https://{GITLAB_USER}:{GITLAB_TOKEN}@code.officialstatistics.org/trade-task-team-phase-1/ais.git\"\n",
    "\n",
    "std_out = subprocess.run([sys.executable, \"-m\", \"pip\", \"install\",git_package], capture_output=True, text=True).stdout\n",
    "print(std_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335e4bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ais import functions as af\n",
    "\n",
    "#still need to register Sedona even with template configuration. need to check why\n",
    "from sedona.register import SedonaRegistrator\n",
    "SedonaRegistrator.registerAll(spark)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from IPython.display import display\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import h3\n",
    "import h3.api.numpy_int as h3int\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "import os\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f45993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get credentials\n",
    "un = \"DennisH3\"\n",
    "pw = getpass.getpass(prompt=\"Please enter PAT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a802a8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load port coordinates\n",
    "#ports = pd.read_csv(\"./ais-data/ODI_Marine_Ports_v0.1.csv\",\n",
    "#                    usecols=['MunicipalityName', 'ERNAME', 'Latitude', 'Longitude'])\n",
    "\n",
    "# Filter for top 20 ports according to https://www144.statcan.gc.ca/nats-stna/tables-tableaux/tbl11-4a/tbl11-4a-CAN-eng.htm\n",
    "# St Romuald is the only one in Lévis\n",
    "# top20 = ['Saint John', 'Montréal', 'Hamilton', 'Halifax', 'Windsor']\n",
    "# ports = ports[(ports['ERNAME'].str.contains('|'.join(top20), case=False)) | \n",
    "#               (ports['MunicipalityName'].isin(['Come-by-Chance', 'St Romuald', 'Victoria'\n",
    "#                                                'Strait of Canso Port(Formerly Port Hawkesbury)',\n",
    "#                                                'Port of Sorel', 'Nanticoke', 'Baie-Comeau',\n",
    "#                                                'Sault-Ste-Marie', 'Port Alfred']))]\n",
    "\n",
    "# Reset index\n",
    "#ports.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Get Long, Lat of top 20 ports\n",
    "ports = {'PortName': ['Port of Vancouver', 'Port of Saint John', 'Port of Quebec',\n",
    "                      'Port of Montreal', 'Come-by-Chance', 'Sept-Iles', 'Strait of Canso Port',\n",
    "                      'Prince Rupert', 'Port-Cartier', 'Offshore (St. John\\'s)', 'Hamilton', 'Halifax',\n",
    "                      'Thunder Bay', 'Sorel', 'Nanticoke', 'Baie-Comeau', 'Sault-Ste-Marie',\n",
    "                      'East Coast Vancouver Island (Victoria)', 'Windsor', 'Port-Alfred'],\n",
    "         'Latitude': [49.2854, 45.4796, 46.821, 45.547, 47.7985, 50.2133, 45.3363,\n",
    "                      54.2883, 50.0326, 53.1355, 43.2732, 44.636, 48.41, 46.0333,\n",
    "                      42.7944, 49.2333, 46.5166, 48.4236, 42.2827, 48.3333],\n",
    "         'Longitude': [-123.0805, -66.0628, -71.204, -73.53, -54.0186, -66.3758, -60.9944,\n",
    "                       -130.3562, -66.8908, -57.6604, -79.8622, -63.551, -89.195, -73.1166,\n",
    "                       -80.0543, -68.1333, -84.3833, -123.3681, -83.0871, -70.8666]\n",
    "        }\n",
    "\n",
    "ports = pd.DataFrame(ports)\n",
    "display(ports)\n",
    "\n",
    "# Recommended to try resolution sizes of 6-9 from Port Indicators Demo\n",
    "# Use resolution 8 with radius of 2\n",
    "ports['H3_int_index_8'] = ports[['Latitude','Longitude']].apply(lambda x: h3.geo_to_h3(x[0],x[1], 8), axis=1)\n",
    "ports['h8_rings'] = ports['H3_int_index_8'].apply(lambda x: list(h3.k_ring(x, 2)))\n",
    "ports = ports.explode('h8_rings', ignore_index=True)\n",
    "ports['h8_rings_decimal'] = ports['h8_rings'].apply(lambda x: int(x, 16))\n",
    "ports = ports['h8_rings_decimal'].unique().tolist()\n",
    "\n",
    "print(len(ports))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eb8dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Get data from earliest date to 2022-08-01\n",
    "start_date = datetime.fromisoformat(\"2019-09-01 00:00:00\") # Earliest date (2018-12-01)\n",
    "end_date = start_date + pd.DateOffset(months=1, seconds=-1) # Last day of month at 23:59:59\n",
    "\n",
    "df = af.get_ais(spark,\n",
    "                start_date=start_date,\n",
    "                end_date=end_date,\n",
    "                h3_list=ports)\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850a657e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique values in vessel_type_cargo and vessel_class\n",
    "# df.select('vessel_type').distinct().show(n=50, truncate=False)\n",
    "\n",
    "# Output:\n",
    "# +------------------------------------+\n",
    "# |vessel_type                         |\n",
    "# +------------------------------------+\n",
    "# |Sailing                             |\n",
    "# |Tanker                              |\n",
    "# |Military                            |\n",
    "# |Towing                              |\n",
    "# |Reserved                            |\n",
    "# |SAR                                 |\n",
    "# |Unknown                             |\n",
    "# |UNAVAILABLE                         |\n",
    "# |Other                               |\n",
    "# |Tug                                 |\n",
    "# |Law Enforcement                     |\n",
    "# |Pleasure Craft                      |\n",
    "# |Passenger                           |\n",
    "# |Diving                              |\n",
    "# |Fishing                             |\n",
    "# |Port Tender                         |\n",
    "# |Spare                               |\n",
    "# |Pilot                               |\n",
    "# |WIG                                 |\n",
    "# |Dredging                            |\n",
    "# |Not Available                       |\n",
    "# |Cargo                               |\n",
    "# |Vessel With Anti-Pollution Equipment|\n",
    "# |HSC                                 |\n",
    "# +------------------------------------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33b4be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by vessel type\n",
    "# vessel_list = ['Cargo', 'Tanker']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a890b83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Try to convert it to pandas df\n",
    "try:\n",
    "    df = df.toPandas()\n",
    "    display(df)\n",
    "    print(df['dt_pos_utc'].min())\n",
    "    print(df['dt_pos_utc'].max())\n",
    "except:\n",
    "    print(\"The dataframe was too large to convert to Pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "890caffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletedProcess(args=['git', 'clone', 'https://github.com/CSBP-CPSE/ais-data.git'], returncode=0, stdout='', stderr=\"Cloning into 'ais-data'...\\nChecking out files:  19% (8/42)   \\nChecking out files:  21% (9/42)   \\nChecking out files:  23% (10/42)   \\nChecking out files:  26% (11/42)   \\nChecking out files:  28% (12/42)   \\nChecking out files:  30% (13/42)   \\nChecking out files:  33% (14/42)   \\nChecking out files:  35% (15/42)   \\nChecking out files:  38% (16/42)   \\nChecking out files:  40% (17/42)   \\nChecking out files:  42% (18/42)   \\nChecking out files:  45% (19/42)   \\nChecking out files:  47% (20/42)   \\nChecking out files:  50% (21/42)   \\nChecking out files:  52% (22/42)   \\nChecking out files:  54% (23/42)   \\nChecking out files:  57% (24/42)   \\nChecking out files:  59% (25/42)   \\nChecking out files:  61% (26/42)   \\nChecking out files:  64% (27/42)   \\nChecking out files:  66% (28/42)   \\nChecking out files:  69% (29/42)   \\nChecking out files:  71% (30/42)   \\nChecking out files:  73% (31/42)   \\nChecking out files:  76% (32/42)   \\nChecking out files:  78% (33/42)   \\nChecking out files:  80% (34/42)   \\nChecking out files:  83% (35/42)   \\nChecking out files:  85% (36/42)   \\nChecking out files:  88% (37/42)   \\nChecking out files:  90% (38/42)   \\nChecking out files:  92% (39/42)   \\nChecking out files:  95% (40/42)   \\nChecking out files:  97% (41/42)   \\nChecking out files: 100% (42/42)   \\nChecking out files: 100% (42/42), done.\\n\")\n",
      "['.git', '.ipynb_checkpoints', 'Data', 'ODI_Marine_Ports_v0.1.csv', 'README.md', 'ais_analysis.ipynb', 'export_data.ipynb', 'move_data.ipynb', 'ship_registry.ipynb', 'vancouver_port.ipynb']\n"
     ]
    }
   ],
   "source": [
    "# Get clone the repo\n",
    "try:\n",
    "    std_out = subprocess.run([\"git\", \"clone\", \"https://github.com/CSBP-CPSE/ais-data.git\"],\n",
    "                             capture_output=True,\n",
    "                             text=True)\n",
    "    print(std_out)\n",
    "    \n",
    "    # Create Data folder if it doesn't exist\n",
    "    if os.path.exists(\"./ais-data/Data/\") is False:\n",
    "        os.mkdir(\"./ais-data/Data/\")\n",
    "    \n",
    "    print(os.listdir(\"./ais-data/\"))\n",
    "except:\n",
    "    print(\"Cloning repo failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e2d0c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 47.3 s, sys: 1.48 s, total: 48.8 s\n",
      "Wall time: 48.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Split DF into smaller files and save them to csv\n",
    "# Each file will have 100000 rows\n",
    "list_df = np.array_split(df, (len(df.index) // 100000) + 1)\n",
    "\n",
    "for i in range(len(list_df)):\n",
    "    list_df[i].to_csv(\"./ais-data/Data/top20_ports_{}_to_{}_chunk_{}.csv\".format(datetime.date(start_date),\n",
    "                                                                                 datetime.date(end_date),\n",
    "                                                                                 i), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7668846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['top20_ports_2019-06-01_to_2019-06-30_chunk_0.csv', 'top20_ports_2019-06-01_to_2019-06-30_chunk_1.csv', 'top20_ports_2019-06-01_to_2019-06-30_chunk_10.csv', 'top20_ports_2019-06-01_to_2019-06-30_chunk_11.csv', 'top20_ports_2019-06-01_to_2019-06-30_chunk_12.csv', 'top20_ports_2019-06-01_to_2019-06-30_chunk_13.csv', 'top20_ports_2019-06-01_to_2019-06-30_chunk_14.csv', 'top20_ports_2019-06-01_to_2019-06-30_chunk_2.csv', 'top20_ports_2019-06-01_to_2019-06-30_chunk_3.csv', 'top20_ports_2019-06-01_to_2019-06-30_chunk_4.csv', 'top20_ports_2019-06-01_to_2019-06-30_chunk_5.csv', 'top20_ports_2019-06-01_to_2019-06-30_chunk_6.csv', 'top20_ports_2019-06-01_to_2019-06-30_chunk_7.csv', 'top20_ports_2019-06-01_to_2019-06-30_chunk_8.csv', 'top20_ports_2019-06-01_to_2019-06-30_chunk_9.csv', 'top20_ports_2019-07-01_to_2019-07-31_chunk_0.csv', 'top20_ports_2019-07-01_to_2019-07-31_chunk_1.csv', 'top20_ports_2019-07-01_to_2019-07-31_chunk_10.csv', 'top20_ports_2019-07-01_to_2019-07-31_chunk_11.csv', 'top20_ports_2019-07-01_to_2019-07-31_chunk_12.csv', 'top20_ports_2019-07-01_to_2019-07-31_chunk_13.csv', 'top20_ports_2019-07-01_to_2019-07-31_chunk_14.csv', 'top20_ports_2019-07-01_to_2019-07-31_chunk_2.csv', 'top20_ports_2019-07-01_to_2019-07-31_chunk_3.csv', 'top20_ports_2019-07-01_to_2019-07-31_chunk_4.csv', 'top20_ports_2019-07-01_to_2019-07-31_chunk_5.csv', 'top20_ports_2019-07-01_to_2019-07-31_chunk_6.csv', 'top20_ports_2019-07-01_to_2019-07-31_chunk_7.csv', 'top20_ports_2019-07-01_to_2019-07-31_chunk_8.csv', 'top20_ports_2019-07-01_to_2019-07-31_chunk_9.csv', 'top20_ports_2019-08-01_to_2019-08-31_chunk_0.csv', 'top20_ports_2019-08-01_to_2019-08-31_chunk_1.csv', 'top20_ports_2019-08-01_to_2019-08-31_chunk_2.csv', 'top20_ports_2019-08-01_to_2019-08-31_chunk_3.csv', 'top20_ports_2019-08-01_to_2019-08-31_chunk_4.csv', 'top20_ports_2019-08-01_to_2019-08-31_chunk_5.csv', 'top20_ports_2019-08-01_to_2019-08-31_chunk_6.csv', 'top20_ports_2019-08-01_to_2019-08-31_chunk_7.csv', 'top20_ports_2019-08-01_to_2019-08-31_chunk_8.csv', 'top20_ports_2019-08-01_to_2019-08-31_chunk_9.csv', 'top20_ports_2019-08-01_to_2019-08-31_chunk_10.csv', 'top20_ports_2019-08-01_to_2019-08-31_chunk_11.csv', 'top20_ports_2019-08-01_to_2019-08-31_chunk_12.csv', 'top20_ports_2019-08-01_to_2019-08-31_chunk_13.csv', 'top20_ports_2019-08-01_to_2019-08-31_chunk_14.csv']\n"
     ]
    }
   ],
   "source": [
    "# Change directory\n",
    "os.chdir(\"./ais-data\")\n",
    "print(os.listdir(\"./Data/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2778ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletedProcess(args=['git', 'config', '--global', 'user.email', '\"dennishuynh3@gmail.com\"'], returncode=0, stdout='', stderr='')\n",
      "CompletedProcess(args=['git', 'config', '--global', 'user.name', '\"DennisH3\"'], returncode=0, stdout='', stderr='')\n",
      "CompletedProcess(args=['git', 'add', '.'], returncode=0, stdout='', stderr='')\n",
      "[main e9f0dc4] Upload data\n",
      " 15 files changed, 1454951 insertions(+)\n",
      " create mode 100644 Data/top20_ports_2019-08-01_to_2019-08-31_chunk_0.csv\n",
      " create mode 100644 Data/top20_ports_2019-08-01_to_2019-08-31_chunk_1.csv\n",
      " create mode 100644 Data/top20_ports_2019-08-01_to_2019-08-31_chunk_10.csv\n",
      " create mode 100644 Data/top20_ports_2019-08-01_to_2019-08-31_chunk_11.csv\n",
      " create mode 100644 Data/top20_ports_2019-08-01_to_2019-08-31_chunk_12.csv\n",
      " create mode 100644 Data/top20_ports_2019-08-01_to_2019-08-31_chunk_13.csv\n",
      " create mode 100644 Data/top20_ports_2019-08-01_to_2019-08-31_chunk_14.csv\n",
      " create mode 100644 Data/top20_ports_2019-08-01_to_2019-08-31_chunk_2.csv\n",
      " create mode 100644 Data/top20_ports_2019-08-01_to_2019-08-31_chunk_3.csv\n",
      " create mode 100644 Data/top20_ports_2019-08-01_to_2019-08-31_chunk_4.csv\n",
      " create mode 100644 Data/top20_ports_2019-08-01_to_2019-08-31_chunk_5.csv\n",
      " create mode 100644 Data/top20_ports_2019-08-01_to_2019-08-31_chunk_6.csv\n",
      " create mode 100644 Data/top20_ports_2019-08-01_to_2019-08-31_chunk_7.csv\n",
      " create mode 100644 Data/top20_ports_2019-08-01_to_2019-08-31_chunk_8.csv\n",
      " create mode 100644 Data/top20_ports_2019-08-01_to_2019-08-31_chunk_9.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Git Config\n",
    "std_out = subprocess.run([\"git\", \"config\", \"--global\", \"user.email\", '\"dennishuynh3@gmail.com\"'], capture_output=True, text=True)\n",
    "print(std_out)\n",
    "std_out = subprocess.run([\"git\", \"config\", \"--global\", \"user.name\", '\"DennisH3\"'], capture_output=True, text=True)\n",
    "print(std_out)\n",
    "\n",
    "# Git add and commit\n",
    "std_out = subprocess.run([\"git\", \"add\", \".\"], capture_output=True, text=True)\n",
    "print(std_out)\n",
    "std_out = subprocess.run([\"git\", \"commit\", \"-m\", \"Upload data\"], capture_output=True, text=True).stdout\n",
    "print(std_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d5d55c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: warning: See http://git.io/iEPt8g for more information.        \n",
      "remote: warning: File Data/top20_ports_2019-08-01_to_2019-08-31_chunk_6.csv is 64.40 MB; this is larger than GitHub's recommended maximum file size of 50.00 MB        \n",
      "remote: warning: File Data/top20_ports_2019-08-01_to_2019-08-31_chunk_3.csv is 64.17 MB; this is larger than GitHub's recommended maximum file size of 50.00 MB        \n",
      "remote: warning: File Data/top20_ports_2019-08-01_to_2019-08-31_chunk_2.csv is 64.23 MB; this is larger than GitHub's recommended maximum file size of 50.00 MB        \n",
      "remote: warning: File Data/top20_ports_2019-08-01_to_2019-08-31_chunk_8.csv is 64.45 MB; this is larger than GitHub's recommended maximum file size of 50.00 MB        \n",
      "remote: warning: File Data/top20_ports_2019-08-01_to_2019-08-31_chunk_1.csv is 64.20 MB; this is larger than GitHub's recommended maximum file size of 50.00 MB        \n",
      "remote: warning: File Data/top20_ports_2019-08-01_to_2019-08-31_chunk_0.csv is 64.34 MB; this is larger than GitHub's recommended maximum file size of 50.00 MB        \n",
      "remote: warning: File Data/top20_ports_2019-08-01_to_2019-08-31_chunk_14.csv is 64.34 MB; this is larger than GitHub's recommended maximum file size of 50.00 MB        \n",
      "remote: warning: File Data/top20_ports_2019-08-01_to_2019-08-31_chunk_11.csv is 64.40 MB; this is larger than GitHub's recommended maximum file size of 50.00 MB        \n",
      "remote: warning: File Data/top20_ports_2019-08-01_to_2019-08-31_chunk_10.csv is 64.26 MB; this is larger than GitHub's recommended maximum file size of 50.00 MB        \n",
      "remote: warning: File Data/top20_ports_2019-08-01_to_2019-08-31_chunk_9.csv is 64.33 MB; this is larger than GitHub's recommended maximum file size of 50.00 MB        \n",
      "remote: warning: File Data/top20_ports_2019-08-01_to_2019-08-31_chunk_7.csv is 64.41 MB; this is larger than GitHub's recommended maximum file size of 50.00 MB        \n",
      "remote: warning: File Data/top20_ports_2019-08-01_to_2019-08-31_chunk_5.csv is 64.39 MB; this is larger than GitHub's recommended maximum file size of 50.00 MB        \n",
      "remote: warning: File Data/top20_ports_2019-08-01_to_2019-08-31_chunk_4.csv is 64.32 MB; this is larger than GitHub's recommended maximum file size of 50.00 MB        \n",
      "remote: warning: File Data/top20_ports_2019-08-01_to_2019-08-31_chunk_13.csv is 64.22 MB; this is larger than GitHub's recommended maximum file size of 50.00 MB        \n",
      "remote: warning: File Data/top20_ports_2019-08-01_to_2019-08-31_chunk_12.csv is 64.31 MB; this is larger than GitHub's recommended maximum file size of 50.00 MB        \n",
      "remote: warning: GH001: Large files detected. You may want to try Git Large File Storage - https://git-lfs.github.com.        \n",
      "To https://github.com/CSBP-CPSE/ais-data.git\n",
      "   0c86300..e9f0dc4  main -> main\n",
      "\n",
      "CPU times: user 24.7 ms, sys: 108 ms, total: 133 ms\n",
      "Wall time: 3min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "push = \"git push --repo https://{}:{}@github.com/CSBP-CPSE/ais-data.git\".format(un, pw)\n",
    "\n",
    "std_out = subprocess.run([push], capture_output=True, text=True, shell=True).stderr\n",
    "print(std_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd4b4b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Config template \"newparquet-20220310\"",
   "language": "python3",
   "name": "newparquet-20220310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
